{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn import neighbors, cluster\n",
    "from sklearn.metrics import pairwise\n",
    "from sklearn.manifold import SpectralEmbedding\n",
    "\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import pygsp\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def create_graph_from_embedding(embedding, name, k=10, n_clusters=8):\n",
    "    latent_dim, batch_size = embedding.shape\n",
    "    if name =='gaussian':\n",
    "        # Compute a gaussian kernel over the node activations\n",
    "        node_distances = squareform(pdist(embedding, 'sqeuclidean'))\n",
    "        s = 1\n",
    "        K = np.exp(-node_distances / s**2)\n",
    "        K[K < 0.1] = 0\n",
    "        A = K * (np.ones((latent_dim, latent_dim)) - np.identity(latent_dim))\n",
    "        return A\n",
    "    elif name == 'knn':\n",
    "        mat = neighbors.kneighbors_graph(embedding, n_neighbors=k, metric='cosine', mode='distance')\n",
    "        mat.data = 1 - mat.data\n",
    "        A = mat.toarray()\n",
    "        A = (A + A.T) / 2\n",
    "        return A\n",
    "    elif name == 'knn-flat':\n",
    "        A = neighbors.kneighbors_graph(embedding, n_neighbors=k, metric='cosine').toarray()\n",
    "        A = (A + A.T) / 2\n",
    "        return A\n",
    "    elif name == 'adaptive': # It's super slow\n",
    "        # Find distance of k-th nearest neighbor and set as bandwidth\n",
    "        neigh = neighbors.NearestNeighbors(n_neighbors=3)\n",
    "        neigh.fit(embedding)\n",
    "        dist, _ = neigh.kneighbors(embedding, return_distance=True)\n",
    "        kdist = dist[:,-1]\n",
    "        # Apply gaussian kernel with adaptive bandwidth\n",
    "        node_distances = squareform(pdist(embedding, 'sqeuclidean'))\n",
    "        K = np.exp(-node_distances / kdist**2)\n",
    "        A = K * (np.ones((latent_dim, latent_dim)) - np.identity(latent_dim))\n",
    "        A = (A + np.transpose(A)) / 2 # Symmetrize knn graph\n",
    "        return A\n",
    "    elif name == 'full':\n",
    "        A = pairwise.cosine_similarity(embedding)\n",
    "        np.fill_diagonal(A, 0)\n",
    "        return np.maximum(A, 0)\n",
    "    elif name == 'hclust':\n",
    "        d = pairwise.cosine_distances(embedding)\n",
    "        clusts = cluster.AgglomerativeClustering(n_clusters=n_clusters, affinity=\"precomputed\", linkage=\"average\").fit(d).labels_\n",
    "        A = np.zeros(d.shape)\n",
    "        for i in range(clusts.max() + 1):\n",
    "            A[np.ix_(clusts == i, clusts == i)] = 1.0\n",
    "\n",
    "        np.fill_diagonal(A, 0)\n",
    "        return A\n",
    "    elif 'knn-spectral':\n",
    "        mat = neighbors.kneighbors_graph(embedding, n_neighbors=k, metric='cosine', mode='distance')\n",
    "        mat.data = 1 - mat.data\n",
    "        A = mat.toarray()\n",
    "        A = (A + A.T) / 2\n",
    "        clusts = cluster.SpectralClustering(n_clusters=n_clusters, affinity='precomputed').fit(A).labels_\n",
    "\n",
    "        mask = np.zeros(A.shape)\n",
    "        for i in range(clusts.max() + 1):\n",
    "            mask[np.ix_(clusts == i, clusts == i)] = 1.0\n",
    "\n",
    "        return (A > 1e-5) * mask\n",
    "    else:\n",
    "        raise RuntimeError('Unknown graph name %s' % name)\n",
    "\n",
    "\n",
    "def create_lap_from_embedding(embedding, *args, **kwargs):\n",
    "    adj_mat = create_graph_from_embedding(embedding, *args, **kwargs)\n",
    "    graph = pygsp.graphs.Graph(adj_mat)\n",
    "    graph.compute_laplacian(lap_type='normalized')\n",
    "    return torch.Tensor(graph.L.A)\n",
    "\n",
    "\n",
    "def graph_loss(activations, lap):\n",
    "    return (activations.mm(lap) * activations).sum() / activations.shape[1]\n",
    "\n",
    "\n",
    "def create_graph_from_layered_embedding(embs, frac:float = 0.1, n_clusters:int = 0):\n",
    "    n_hidden = len(embs)\n",
    "    layers = [e.shape[0] for e in embs]\n",
    "\n",
    "    neighs = [neighbors.NearestNeighbors(n_neighbors=int(frac * layers[i] + 1), metric='cosine').fit(embs[i]) for i in range(n_hidden)]\n",
    "    ids_per_layer = [sum(layers[:i]) + np.arange(layers[i], dtype=int) for i in range(n_hidden)]\n",
    "\n",
    "    adj_mat = np.zeros((sum(layers), sum(layers)))\n",
    "\n",
    "    for i in range(n_hidden):\n",
    "        dist, ids = [x[:, 1:] for x in neighs[i].kneighbors(embs[i], return_distance=True)]\n",
    "        for v1,v2s in enumerate(ids):\n",
    "            adj_mat[ids_per_layer[i][v1], ids_per_layer[i][v2s]] = 1 - dist[v1,:]\n",
    "\n",
    "        if i != n_hidden - 1:\n",
    "            dist, ids = [x[:, :-1] for x in neighs[i + 1].kneighbors(embs[i], return_distance=True)]\n",
    "            for v1,v2s in enumerate(ids):\n",
    "                adj_mat[ids_per_layer[i][v1], ids_per_layer[i + 1][v2s]] = 1 - dist[v1,:]\n",
    "\n",
    "        if i != 0:\n",
    "            dist, ids = [x[:, :-1] for x in neighs[i - 1].kneighbors(embs[i], return_distance=True)]\n",
    "            for v1,v2s in enumerate(ids):\n",
    "                adj_mat[ids_per_layer[i][v1], ids_per_layer[i - 1][v2s]] = 1 - dist[v1,:]\n",
    "\n",
    "    adj_mat = (adj_mat + adj_mat.T) / 2\n",
    "\n",
    "    if n_clusters <= 0:\n",
    "        return adj_mat\n",
    "\n",
    "    clusts = cluster.SpectralClustering(n_clusters=n_clusters, affinity='precomputed').fit(adj_mat).labels_\n",
    "\n",
    "    mask = np.zeros_like(adj_mat)\n",
    "    for i in range(clusts.max() + 1):\n",
    "        mask[np.ix_(clusts == i, clusts == i)] = 1.0\n",
    "\n",
    "    return (adj_mat > 1e-5) * mask"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "necessary-package",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import gc\n",
    "import collections\n",
    "from functools import partial\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "dev = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sunset-small",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, layers, drop_p=0.2):\n",
    "        super(Net,self).__init__()\n",
    "        self.hidden = nn.ModuleList()\n",
    "        for li,lo in zip(layers, layers[1:]):\n",
    "            self.hidden.append(nn.Linear(li, lo))\n",
    "        self.droput = nn.Dropout(drop_p)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = x.view(-1, INPUT_SHAPE)\n",
    "        for i,l in enumerate(self.hidden):\n",
    "            x = l(x)\n",
    "            if i < len(self.hidden) - 1:\n",
    "                x = self.droput(F.relu(x))\n",
    "        return x\n",
    "\n",
    "def eval_nn(nn, testloader):\n",
    "    correct = 0\n",
    "    loss_sublist = []\n",
    "    for x,y in testloader:\n",
    "        x,y = x.to(dev), y.to(dev)\n",
    "        nn.eval()\n",
    "        z = nn(x)\n",
    "        _, yh = torch.max(z.data, 1)\n",
    "        correct += (yh == y).sum().item()\n",
    "        loss_sublist.append(crit(z, y).data.item())\n",
    "    acc = correct / n_test\n",
    "    return acc, round(np.mean(loss_sublist), 4)\n",
    "\n",
    "def run_nn_train(nn, x, y, optimizer, crit):\n",
    "    x,y = x.to(dev), y.to(dev)\n",
    "    nn.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = nn(x)\n",
    "    return crit(z, y)\n",
    "\n",
    "def clean_mem():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "twenty-montana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e2d57d2b73046de922a87f600811dd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26421880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1fe734299ab47948532c96c5b67dce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f1ac37d07e8494584dbd53f07cada54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4422102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "187d1e8ba8f34f5e8b57ca08a62f8f67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\gurkenglas\\.virtualenvs\\graphregularizednns\\lib\\site-packages\\torchvision\\datasets\\mnist.py:502: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:143.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\gurkenglas\\.virtualenvs\\graphregularizednns\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:474: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 4 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "trainset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainset_raw = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1024, shuffle=True, num_workers=12)\n",
    "\n",
    "testset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1024, shuffle=False, num_workers=12)\n",
    "\n",
    "INPUT_SHAPE = 1 * 28 * 28\n",
    "OUTPUT_SHAPE = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weird-gambling",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Simple MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "combined-tuition",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-7-526de3ba966b>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mlayers\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mINPUT_SHAPE\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m40\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m40\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m30\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mOUTPUT_SHAPE\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mmlp\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mNet\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlayers\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdrop_p\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0.3\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdev\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mcrit\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mCrossEntropyLoss\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0moptimizer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptim\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mAdam\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmlp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlr\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0.001\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\gurkenglas\\.virtualenvs\\graphregularizednns\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36mto\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    671\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_floating_point\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_complex\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32melse\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_blocking\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    672\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 673\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mconvert\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    674\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    675\u001B[0m     def register_backward_hook(\n",
      "\u001B[1;32mc:\\users\\gurkenglas\\.virtualenvs\\graphregularizednns\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_apply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    385\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_apply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    386\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 387\u001B[1;33m             \u001B[0mmodule\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    388\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    389\u001B[0m         \u001B[1;32mdef\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtensor_applied\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\gurkenglas\\.virtualenvs\\graphregularizednns\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_apply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    385\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_apply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    386\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 387\u001B[1;33m             \u001B[0mmodule\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    388\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    389\u001B[0m         \u001B[1;32mdef\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtensor_applied\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\gurkenglas\\.virtualenvs\\graphregularizednns\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_apply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    407\u001B[0m                 \u001B[1;31m# `with torch.no_grad():`\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    408\u001B[0m                 \u001B[1;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mno_grad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 409\u001B[1;33m                     \u001B[0mparam_applied\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mparam\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    410\u001B[0m                 \u001B[0mshould_use_set_data\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mparam\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparam_applied\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    411\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0mshould_use_set_data\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\gurkenglas\\.virtualenvs\\graphregularizednns\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36mconvert\u001B[1;34m(t)\u001B[0m\n\u001B[0;32m    669\u001B[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001B[0;32m    670\u001B[0m                             non_blocking, memory_format=convert_to_format)\n\u001B[1;32m--> 671\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_floating_point\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_complex\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32melse\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_blocking\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    672\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    673\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mconvert\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\gurkenglas\\.virtualenvs\\graphregularizednns\\lib\\site-packages\\torch\\cuda\\__init__.py\u001B[0m in \u001B[0;36m_lazy_init\u001B[1;34m()\u001B[0m\n\u001B[0;32m    162\u001B[0m                 \"multiprocessing, you must use the 'spawn' start method\")\n\u001B[0;32m    163\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_C\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'_cuda_getDeviceCount'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 164\u001B[1;33m             \u001B[1;32mraise\u001B[0m \u001B[0mAssertionError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Torch not compiled with CUDA enabled\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    165\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0m_cudart\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    166\u001B[0m             raise AssertionError(\n",
      "\u001B[1;31mAssertionError\u001B[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "layers = [INPUT_SHAPE, 40, 40, 30, OUTPUT_SHAPE]\n",
    "mlp = Net(layers, drop_p=0.3).to(dev)\n",
    "\n",
    "crit = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "neutral-liberal",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<timed exec>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'mlp' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "N_EPOCHS = 20\n",
    "train_loss_list = []\n",
    "test_loss_list = []\n",
    "accuracy_list = []\n",
    "correct = 0\n",
    "n_test = len(testset)\n",
    "graph = None\n",
    "\n",
    "for e in range(N_EPOCHS):\n",
    "    activations = collections.defaultdict(list)\n",
    "    # Train\n",
    "    loss_sublist = []\n",
    "    gl_sublist = []\n",
    "    for x,y in trainloader:\n",
    "        loss = run_nn_train(mlp, x, y, optimizer=optimizer, crit=crit)\n",
    "        loss_sublist.append(loss.data.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    train_loss_list.append(np.mean(loss_sublist))\n",
    "\n",
    "    # Test\n",
    "    acc, test_loss = eval_nn(mlp, testloader)\n",
    "    del x,y,loss\n",
    "    clean_mem()\n",
    "\n",
    "    test_loss_list.append(test_loss)\n",
    "    print(f'{e}. Accuracy: {round(acc, 4)}, CE: {test_loss_list[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amateur-wright",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = dict(mlp.named_modules())['hidden.0']\n",
    "fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(20, 14))\n",
    "for i in range(16):\n",
    "    sns.heatmap(list(l1.parameters())[0][i,:].reshape(28, 28).cpu().detach().numpy(), xticklabels=False, yticklabels=False, center=0, ax=axes.flatten()[i])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weighted-retail",
   "metadata": {},
   "source": [
    "## Graph MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "genuine-arbor",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-9-04357ca5bfc1>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mids_per_layer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0msum\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlayers\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m+\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlayers\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m+\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mint\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mn_hidden\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m \u001B[0mgraph_mlp\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mNet\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlayers\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdrop_p\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0.3\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdev\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[0mcrit\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mCrossEntropyLoss\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\gurkenglas\\.virtualenvs\\graphregularizednns\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36mto\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    671\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_floating_point\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_complex\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32melse\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_blocking\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    672\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 673\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mconvert\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    674\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    675\u001B[0m     def register_backward_hook(\n",
      "\u001B[1;32mc:\\users\\gurkenglas\\.virtualenvs\\graphregularizednns\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_apply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    385\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_apply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    386\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 387\u001B[1;33m             \u001B[0mmodule\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    388\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    389\u001B[0m         \u001B[1;32mdef\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtensor_applied\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\gurkenglas\\.virtualenvs\\graphregularizednns\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_apply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    385\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_apply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    386\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 387\u001B[1;33m             \u001B[0mmodule\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    388\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    389\u001B[0m         \u001B[1;32mdef\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtensor_applied\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\gurkenglas\\.virtualenvs\\graphregularizednns\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_apply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    407\u001B[0m                 \u001B[1;31m# `with torch.no_grad():`\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    408\u001B[0m                 \u001B[1;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mno_grad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 409\u001B[1;33m                     \u001B[0mparam_applied\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mparam\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    410\u001B[0m                 \u001B[0mshould_use_set_data\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mparam\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparam_applied\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    411\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0mshould_use_set_data\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\gurkenglas\\.virtualenvs\\graphregularizednns\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36mconvert\u001B[1;34m(t)\u001B[0m\n\u001B[0;32m    669\u001B[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001B[0;32m    670\u001B[0m                             non_blocking, memory_format=convert_to_format)\n\u001B[1;32m--> 671\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_floating_point\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_complex\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32melse\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_blocking\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    672\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    673\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mconvert\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\gurkenglas\\.virtualenvs\\graphregularizednns\\lib\\site-packages\\torch\\cuda\\__init__.py\u001B[0m in \u001B[0;36m_lazy_init\u001B[1;34m()\u001B[0m\n\u001B[0;32m    162\u001B[0m                 \"multiprocessing, you must use the 'spawn' start method\")\n\u001B[0;32m    163\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_C\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'_cuda_getDeviceCount'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 164\u001B[1;33m             \u001B[1;32mraise\u001B[0m \u001B[0mAssertionError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Torch not compiled with CUDA enabled\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    165\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0m_cudart\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    166\u001B[0m             raise AssertionError(\n",
      "\u001B[1;31mAssertionError\u001B[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "layers = [INPUT_SHAPE, 40, 40, 30, OUTPUT_SHAPE]\n",
    "n_hidden = len(layers) - 2\n",
    "ids_per_layer = [sum(layers[1:(i+1)]) + np.arange(layers[i+1], dtype=int) for i in range(n_hidden)]\n",
    "\n",
    "graph_mlp = Net(layers, drop_p=0.3).to(dev)\n",
    "\n",
    "crit = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(graph_mlp.parameters(), lr=0.001)\n",
    "\n",
    "activations = collections.defaultdict(list)\n",
    "def save_activation(name, mod, inp, out):\n",
    "    activations[name].append(out.cpu())\n",
    "\n",
    "for name, m in graph_mlp.named_modules():\n",
    "    if type(m)==nn.Linear:\n",
    "        m.register_forward_hook(partial(save_activation, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dominant-tutorial",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'graph_mlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<timed exec>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'graph_mlp' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "N_EPOCHS = 20\n",
    "train_loss_list = []\n",
    "test_loss_list = []\n",
    "accuracy_list = []\n",
    "correct = 0\n",
    "n_test = len(testset)\n",
    "lap = None\n",
    "\n",
    "for e in range(N_EPOCHS):\n",
    "    activations = collections.defaultdict(list)\n",
    "    # Train\n",
    "    loss_sublist = []\n",
    "    gl_sublist = []\n",
    "    for x,y in trainloader:\n",
    "        loss = run_nn_train(graph_mlp, x, y, optimizer=optimizer, crit=crit)\n",
    "        loss_sublist.append(loss.data.item())\n",
    "\n",
    "        if lap is not None:\n",
    "            gl = graph_loss(torch.hstack([activations[f'hidden.{li}'][-1] for li in range(n_hidden)]), lap) * 0.005\n",
    "            gl_sublist.append(gl.data.item())\n",
    "            loss += gl\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    train_loss_list.append(np.mean(loss_sublist))\n",
    "    \n",
    "    # Loss update\n",
    "    embs = [torch.vstack(activations[f'hidden.{i}']).T.detach().numpy() for i in range(n_hidden)]\n",
    "    adj_mat = create_graph_from_layered_embedding(embs, frac=0.3)\n",
    "    graph = pygsp.graphs.Graph(adj_mat)\n",
    "    graph.compute_laplacian(lap_type='normalized')\n",
    "    lap = torch.Tensor(graph.L.A)\n",
    "\n",
    "    # Test\n",
    "    acc, test_loss = eval_nn(graph_mlp, testloader)\n",
    "    del x,y,loss\n",
    "    clean_mem()\n",
    "\n",
    "    if len(gl_sublist) > 0:\n",
    "        print(f'{e}. Accuracy: {round(acc, 4)}, CE: {test_loss}, GL: {round(np.mean(gl_sublist), 3)}')\n",
    "    else:\n",
    "        print(f'{e}. Accuracy: {round(acc, 4)}, CE: {test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "favorite-costume",
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = [torch.vstack(activations[f'hidden.{i}']).T.detach().numpy() for i in range(n_hidden)]\n",
    "adj_mat = create_graph_from_layered_embedding(embs, frac=0.3)\n",
    "\n",
    "spec_emb = SpectralEmbedding(affinity='precomputed').fit_transform(adj_mat)\n",
    "clust_labels = cluster.k_means(spec_emb, 8)[1]\n",
    "\n",
    "for i in set(clust_labels):\n",
    "    mask = (clust_labels == i)\n",
    "    plt.scatter(spec_emb[mask,0], spec_emb[mask,1], s=5, label=i)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trained-device",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,ids in enumerate(ids_per_layer):\n",
    "    plt.scatter(spec_emb[ids,0], spec_emb[ids,1], s=5, label=i)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-thought",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = dict(graph_mlp.named_modules())['hidden.0']\n",
    "fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(20, 14))\n",
    "for i in range(16):\n",
    "    sns.heatmap(list(l1.parameters())[0][i,:].reshape(28, 28).cpu().detach().numpy(), xticklabels=False, yticklabels=False, center=0, ax=axes.flatten()[i])\n",
    "\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}